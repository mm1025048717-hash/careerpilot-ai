"""
æ™ºèŒé€š CareerPilot AI - DeepSeek + Agent åŒé‡æž¶æž„
ç®€åŒ–ç‰ˆæœ¬ - ä¸ä¾èµ–å¤æ‚çš„ LangChain Agent
"""
import json
import os
from typing import Dict, List, Any
from openai import OpenAI

# å¯¼å…¥è®°å¿†å’ŒçŸ¥è¯†åº“æ¨¡å—
from memory import conversation_manager, memory_system
from knowledge_base import knowledge_base


def load_config():
    """åŠ è½½ç”¨æˆ·é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), 'user_config.json')
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


class SemanticUnderstanding:
    """è¯­ä¹‰ç†è§£å±‚ - ä½¿ç”¨ DeepSeek è¿›è¡Œæ·±åº¦è¯­ä¹‰åˆ†æž"""
    
    def __init__(self):
        config = load_config()
        self.api_key = config.get('deepseekApiKey', os.getenv('DEEPSEEK_API_KEY', ''))
        self.base_url = config.get('deepseekBaseUrl', 'https://api.deepseek.com')
    
    def _get_llm(self):
        return OpenAI(api_key=self.api_key, base_url=self.base_url)
    
    def understand(self, user_input: str, conversation_history: List[Dict] = None, user_profile: str = "") -> Dict:
        """æ·±åº¦ç†è§£ç”¨æˆ·è¾“å…¥"""
        config = load_config()
        llm = self._get_llm()
        
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¯­ä¹‰ç†è§£ä¸“å®¶ã€‚åˆ†æžç”¨æˆ·è¾“å…¥å¹¶æå–ç»“æž„åŒ–ä¿¡æ¯ã€‚

ç”¨æˆ·ç”»åƒï¼š{user_profile}

ç”¨æˆ·é…ç½®ï¼š
- å§“åï¼š{config.get('name', 'æœªçŸ¥')}
- ç›®æ ‡åŸŽå¸‚ï¼š{config.get('targetCity', 'åŒ—äº¬')}
- ç›®æ ‡å²—ä½ï¼š{config.get('targetRole', '')}
- æœŸæœ›è–ªèµ„ï¼š{config.get('salary', '')}

è¯·åˆ†æžç”¨æˆ·è¾“å…¥ï¼Œè¿”å›žJSONæ ¼å¼ï¼š
{{
    "intent": "æ„å›¾ç±»åž‹: apply_job/search_job/optimize_resume/interview_prep/general_chat/knowledge_query/preference_update",
    "entities": {{
        "keyword": "èŒä½å…³é”®è¯ï¼ˆå¦‚æœ‰ï¼‰",
        "city": "åŸŽå¸‚ï¼ˆå¦‚æœ‰ï¼Œå¦åˆ™ç”¨é»˜è®¤ï¼‰",
        "count": "æ•°é‡ï¼ˆé»˜è®¤5ï¼‰"
    }},
    "sentiment": "æƒ…æ„Ÿ: positive/negative/neutral",
    "confidence": 0.9
}}

åªè¿”å›žJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        messages = [{"role": "system", "content": system_prompt}]
        
        if conversation_history:
            for msg in conversation_history[-6:]:
                messages.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})
        
        messages.append({"role": "user", "content": user_input})
        
        try:
            response = llm.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
            result_text = response.choices[0].message.content.strip()
            
            if '```json' in result_text:
                result_text = result_text.split('```json')[1].split('```')[0]
            elif '```' in result_text:
                result_text = result_text.split('```')[1].split('```')[0]
            
            return json.loads(result_text)
        except Exception as e:
            print(f"è¯­ä¹‰ç†è§£å‡ºé”™: {e}")
            return {"intent": "general_chat", "entities": {}, "sentiment": "neutral", "confidence": 0.5}


class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå±‚"""
    
    def __init__(self):
        self.tasks_file = os.path.join(os.path.dirname(__file__), 'user_tasks.json')
    
    def execute_apply_task(self, keyword: str, city: str, count: int = 5) -> Dict:
        """åˆ›å»ºæŠ•é€’ä»»åŠ¡"""
        import uuid
        from datetime import datetime
        
        task = {
            "id": str(uuid.uuid4()),
            "type": "apply",
            "keyword": keyword,
            "city": city,
            "count": count,
            "status": "pending",
            "created_at": datetime.now().isoformat(),
            "progress": 0
        }
        
        tasks = self._load_tasks()
        tasks.append(task)
        self._save_tasks(tasks)
        
        return {"success": True, "task_id": task["id"], "message": f"å·²åˆ›å»ºæŠ•é€’ä»»åŠ¡ï¼šåœ¨{city}æŠ•é€’{count}ä¸ª{keyword}å²—ä½", "task": task}
    
    def search_knowledge(self, query: str, doc_type: str = None) -> str:
        """æœç´¢çŸ¥è¯†åº“"""
        context = knowledge_base.get_context_for_ai(query, doc_type)
        return context if context else "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
    
    def update_preference(self, key: str, value: Any) -> Dict:
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        memory_system.update_preference(key, value)
        return {"success": True, "message": f"å·²è®°ä½ä½ çš„åå¥½ï¼š{key} = {value}"}
    
    def _load_tasks(self) -> List[Dict]:
        if os.path.exists(self.tasks_file):
            with open(self.tasks_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    
    def _save_tasks(self, tasks: List[Dict]):
        with open(self.tasks_file, 'w', encoding='utf-8') as f:
            json.dump(tasks, f, ensure_ascii=False, indent=2)


class DualAgent:
    """åŒé‡æž¶æž„ Agent - ç»“åˆè¯­ä¹‰ç†è§£å’Œä»»åŠ¡æ‰§è¡Œ"""
    
    def __init__(self):
        self.semantic = SemanticUnderstanding()
        self.executor = TaskExecutor()
    
    def _get_llm(self):
        config = load_config()
        return OpenAI(
            api_key=config.get('deepseekApiKey', os.getenv('DEEPSEEK_API_KEY', '')),
            base_url=config.get('deepseekBaseUrl', 'https://api.deepseek.com')
        )
    
    def run(self, user_input: str, conversation_id: str = None) -> str:
        """è¿è¡ŒåŒé‡æž¶æž„å¤„ç†"""
        result = self.run_with_details(user_input, conversation_id)
        return result.get("response", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚")
    
    def run_with_details(self, user_input: str, conversation_id: str = None) -> Dict:
        """è¿è¡Œå¹¶è¿”å›žè¯¦ç»†ç»“æžœ"""
        try:
            # èŽ·å–å¯¹è¯åŽ†å²
            history = []
            if conversation_id:
                history = conversation_manager.get_messages(conversation_id)
            
            # èŽ·å–ç”¨æˆ·ç”»åƒ
            user_profile = memory_system.get_user_profile_summary()
            
            # ç¬¬ä¸€å±‚ï¼šè¯­ä¹‰ç†è§£
            understanding = self.semantic.understand(user_input, history, user_profile)
            print(f"è¯­ä¹‰ç†è§£ç»“æžœ: {understanding}")
            
            # ç¬¬äºŒå±‚ï¼šæ ¹æ®æ„å›¾æ‰§è¡Œä»»åŠ¡
            task_created = None
            intent = understanding.get("intent", "general_chat")
            entities = understanding.get("entities", {})
            
            # å¤„ç†æŠ•é€’ä»»åŠ¡
            if intent == "apply_job":
                config = load_config()
                keyword = entities.get("keyword") or config.get("targetRole", "äº§å“ç»ç†")
                city = entities.get("city") or config.get("targetCity", "åŒ—äº¬")
                count = int(entities.get("count", 5))
                
                task_result = self.executor.execute_apply_task(keyword, city, count)
                task_created = task_result.get("task")
            
            # ç”Ÿæˆå›žå¤
            response = self._generate_response(user_input, understanding, history, task_created)
            
            # ç”Ÿæˆæ™ºèƒ½æŽ¨èï¼ˆé—®é¢˜å’ŒåŠ¨ä½œï¼‰
            suggestions = self._generate_suggestions(user_input, understanding, task_created)
            
            # ä¿å­˜å¯¹è¯
            if conversation_id:
                conversation_manager.add_message(conversation_id, "user", user_input)
                conversation_manager.add_message(conversation_id, "assistant", response)
            
            return {
                "response": response,
                "understanding": understanding,
                "task_created": task_created,
                "suggestions": suggestions
            }
            
        except Exception as e:
            print(f"Agent æ‰§è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return {
                "response": f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™äº†ï¼š{str(e)}",
                "understanding": {},
                "task_created": None
            }
    
    def _generate_response(self, user_input: str, understanding: Dict, history: List[Dict], task_created: Dict = None) -> str:
        """ç”Ÿæˆè‡ªç„¶è¯­è¨€å›žå¤"""
        try:
            llm = self._get_llm()
            config = load_config()
            
            # æž„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            
            if task_created:
                context_parts.append(f"[å·²åˆ›å»ºä»»åŠ¡] ç±»åž‹: {task_created.get('type')}, å…³é”®è¯: {task_created.get('keyword')}, åŸŽå¸‚: {task_created.get('city')}, æ•°é‡: {task_created.get('count')}")
            
            # èŽ·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
            kb_context = knowledge_base.get_context_for_ai(user_input)
            if kb_context:
                context_parts.append(f"[çŸ¥è¯†åº“] {kb_context[:500]}")
            
            system_prompt = f"""ä½ æ˜¯æ™ºèŒé€šAIåŠ©æ‰‹ï¼Œä¸€ä¸ªä¸“ä¸šå‹å¥½çš„æ±‚èŒé¡¾é—®ã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- å§“åï¼š{config.get('name', 'ç”¨æˆ·')}
- ç›®æ ‡åŸŽå¸‚ï¼š{config.get('targetCity', 'åŒ—äº¬')}
- ç›®æ ‡å²—ä½ï¼š{config.get('targetRole', '')}

è¯­ä¹‰ç†è§£ç»“æžœï¼š{json.dumps(understanding, ensure_ascii=False)}

{chr(10).join(context_parts) if context_parts else ''}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”¨å‹å¥½ä¸“ä¸šçš„è¯­æ°”å›žå¤ç”¨æˆ·ã€‚å¦‚æžœå·²åˆ›å»ºä»»åŠ¡ï¼Œè¯·ç¡®è®¤å¹¶è¯´æ˜ŽåŽç»­æ­¥éª¤ã€‚å›žå¤è¯·ç®€æ´æ˜Žäº†ï¼Œä½¿ç”¨ä¸­æ–‡ã€‚"""

            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ å¯¹è¯åŽ†å²
            for msg in history[-4:]:
                messages.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})
            
            messages.append({"role": "user", "content": user_input})
            
            response = llm.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                temperature=0.7,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ç”Ÿæˆå›žå¤å‡ºé”™: {e}")
            
            # é™çº§å›žå¤
            if task_created:
                return f"å¥½çš„ï¼Œæˆ‘å·²ç»ä¸ºä½ åˆ›å»ºäº†æŠ•é€’ä»»åŠ¡ï¼å°†åœ¨{task_created.get('city')}æŠ•é€’{task_created.get('count')}ä¸ª{task_created.get('keyword')}å²—ä½ã€‚ä»»åŠ¡æ­£åœ¨åŽå°æ‰§è¡Œä¸­ï¼Œä½ å¯ä»¥åœ¨ã€Œä»»åŠ¡ã€é¡µé¢æŸ¥çœ‹è¿›åº¦ã€‚"
            
            return "æ”¶åˆ°ä½ çš„æ¶ˆæ¯äº†ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
    
    def _generate_suggestions(self, user_input: str, understanding: Dict, task_created: Dict = None) -> Dict:
        """æ ¹æ®ç”¨æˆ·æ„å›¾ç”Ÿæˆæ™ºèƒ½æŽ¨è"""
        config = load_config()
        intent = understanding.get("intent", "general_chat")
        entities = understanding.get("entities", {})
        
        # èŽ·å–ç”¨æˆ·é…ç½®
        user_name = config.get("name", "ç”¨æˆ·")
        target_city = config.get("targetCity", "åŒ—äº¬")
        target_role = config.get("targetRole", "äº§å“ç»ç†")
        
        # æŽ¨èé—®é¢˜åˆ—è¡¨
        questions = []
        # æŽ¨èåŠ¨ä½œåˆ—è¡¨
        actions = []
        
        # æ ¹æ®æ„å›¾åŠ¨æ€ç”ŸæˆæŽ¨è
        if task_created:
            # åˆšåˆ›å»ºä»»åŠ¡åŽçš„æŽ¨è
            questions = [
                f"æŸ¥çœ‹å…¶ä»–åŸŽå¸‚çš„{target_role}å²—ä½",
                "å¸®æˆ‘ä¼˜åŒ–ç®€åŽ†",
                "æŸ¥çœ‹ä»»åŠ¡è¿›åº¦"
            ]
            actions = [
                {"label": "ðŸ“Š æŸ¥çœ‹ä»»åŠ¡", "type": "navigate", "target": "tasks"},
                {"label": f"ðŸ” æœç´¢æ›´å¤š{target_role}", "type": "send", "message": f"å¸®æˆ‘æœç´¢æ›´å¤š{target_role}å²—ä½"}
            ]
        elif intent == "apply_job":
            # æŠ•é€’ç›¸å…³
            keyword = entities.get("keyword", target_role)
            city = entities.get("city", target_city)
            questions = [
                f"å¸®æˆ‘æŠ•é€’{city}çš„{keyword}å²—ä½",
                f"æœç´¢æ·±åœ³çš„{keyword}å²—ä½",
                f"æŽ¨èé«˜è–ª{keyword}èŒä½"
            ]
            actions = [
                {"label": f"ðŸš€ ç«‹å³æŠ•é€’ {keyword}", "type": "send", "message": f"å¸®æˆ‘æŠ•é€’{city}çš„{keyword}å²—ä½ï¼ŒæŠ•5ä¸ª"},
                {"label": "ðŸ“ ä¼˜åŒ–ç®€åŽ†", "type": "send", "message": "å¸®æˆ‘ä¼˜åŒ–ç®€åŽ†"}
            ]
        elif intent == "search_job":
            # æœç´¢ç›¸å…³
            questions = [
                f"å¸®æˆ‘æŠ•é€’{target_city}çš„å²—ä½",
                "æŽ¨èäº’è”ç½‘å¤§åŽ‚çš„èŒä½",
                "æŸ¥çœ‹æœ€æ–°çš„æ‹›è˜ä¿¡æ¯"
            ]
            actions = [
                {"label": "ðŸ” å¼€å§‹æœç´¢", "type": "send", "message": f"æœç´¢{target_city}çš„{target_role}å²—ä½"},
                {"label": "ðŸ“‹ æŸ¥çœ‹çŸ¥è¯†åº“", "type": "navigate", "target": "knowledge"}
            ]
        elif intent == "optimize_resume":
            # ç®€åŽ†ä¼˜åŒ–
            questions = [
                "å¸®æˆ‘åˆ†æžç®€åŽ†çš„ä¸è¶³",
                "æŽ¨èç®€åŽ†æ¨¡æ¿",
                "å¦‚ä½•çªå‡ºæˆ‘çš„é¡¹ç›®ç»éªŒ"
            ]
            actions = [
                {"label": "ðŸ“¤ ä¸Šä¼ ç®€åŽ†", "type": "upload", "target": "resume"},
                {"label": "ðŸ’¡ èŽ·å–å»ºè®®", "type": "send", "message": "ç»™æˆ‘ä¸€äº›ç®€åŽ†ä¼˜åŒ–çš„å…·ä½“å»ºè®®"}
            ]
        elif intent == "interview_prep":
            # é¢è¯•å‡†å¤‡
            questions = [
                f"{target_role}å¸¸è§é¢è¯•é—®é¢˜",
                "å¦‚ä½•å›žç­”èŒä¸šè§„åˆ’é—®é¢˜",
                "è–ªèµ„è°ˆåˆ¤æŠ€å·§"
            ]
            actions = [
                {"label": "ðŸ“š é¢è¯•é¢˜åº“", "type": "send", "message": f"ç»™æˆ‘ä¸€äº›{target_role}çš„é¢è¯•é—®é¢˜"},
                {"label": "ðŸŽ¯ æ¨¡æ‹Ÿé¢è¯•", "type": "send", "message": "å¸®æˆ‘æ¨¡æ‹Ÿä¸€æ¬¡é¢è¯•"}
            ]
        else:
            # é€šç”¨æŽ¨è
            questions = [
                f"å¸®æˆ‘æŠ•é€’{target_city}çš„{target_role}å²—ä½",
                "å¸®æˆ‘ä¼˜åŒ–ç®€åŽ†",
                "æŽ¨èä¸€äº›é«˜è–ªèŒä½",
                "é¢è¯•å‡†å¤‡å»ºè®®"
            ]
            actions = [
                {"label": f"ðŸš€ å¿«é€ŸæŠ•é€’", "type": "send", "message": f"å¸®æˆ‘æŠ•é€’{target_city}çš„{target_role}ï¼ŒæŠ•5ä¸ª"},
                {"label": "âš™ï¸ ä¿®æ”¹åå¥½", "type": "navigate", "target": "settings"}
            ]
        
        return {
            "questions": questions[:4],  # æœ€å¤š4ä¸ªé—®é¢˜
            "actions": actions[:3]  # æœ€å¤š3ä¸ªåŠ¨ä½œ
        }


# å…¨å±€å®žä¾‹
dual_agent = DualAgent()


def run_agent(user_input: str, conversation_id: str = None) -> str:
    """è¿è¡Œ Agentï¼ˆå…¼å®¹æ—§æŽ¥å£ï¼‰"""
    return dual_agent.run(user_input, conversation_id)


def run_agent_with_details(user_input: str, conversation_id: str = None) -> Dict:
    """è¿è¡Œ Agent å¹¶è¿”å›žè¯¦ç»†ç»“æžœ"""
    return dual_agent.run_with_details(user_input, conversation_id)


def parse_user_intent(user_input: str) -> Dict:
    """è§£æžç”¨æˆ·æ„å›¾ï¼ˆä¾› Worker ä½¿ç”¨ï¼‰"""
    config = load_config()
    
    # ç®€å•è§£æž
    result = {
        "keyword": config.get("targetRole", "äº§å“ç»ç†"),
        "city": config.get("targetCity", "åŒ—äº¬"),
        "count": 5
    }
    
    # å°è¯•ä»Žè¾“å…¥ä¸­æå–ä¿¡æ¯
    import re
    
    # æå–åŸŽå¸‚
    cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·ž", "æ·±åœ³", "æ­å·ž", "æˆéƒ½", "æ­¦æ±‰", "å—äº¬", "è¥¿å®‰", "è‹å·ž"]
    for city in cities:
        if city in user_input:
            result["city"] = city
            break
    
    # æå–æ•°é‡
    count_match = re.search(r'(\d+)\s*(ä¸ª|ä»½)', user_input)
    if count_match:
        result["count"] = int(count_match.group(1))
    
    # æå–å…³é”®è¯ï¼ˆç®€å•é€»è¾‘ï¼‰
    keywords = ["äº§å“ç»ç†", "å‰ç«¯", "åŽç«¯", "å…¨æ ˆ", "è¿è¥", "è®¾è®¡", "æµ‹è¯•", "æ•°æ®åˆ†æž", "ç®—æ³•", "Java", "Python"]
    for kw in keywords:
        if kw.lower() in user_input.lower():
            result["keyword"] = kw
            break
    
    return result


def execute_apply_task(keyword: str, city: str, count: int) -> int:
    """æ‰§è¡ŒæŠ•é€’ä»»åŠ¡ï¼ˆä¾› Worker ä½¿ç”¨ï¼‰"""
    try:
        from boss_automation import BossAutomation
        
        config = load_config()
        
        bot = BossAutomation(
            keywords=keyword,
            city=city,
            phone=config.get('phone', ''),
            max_apply=count
        )
        
        # æ‰§è¡ŒæŠ•é€’
        applied_count = bot.run()
        return applied_count
        
    except Exception as e:
        print(f"æ‰§è¡ŒæŠ•é€’å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0
